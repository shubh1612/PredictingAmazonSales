{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predict.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LeOakWfVdT67",
        "colab_type": "code",
        "outputId": "284222b8-06d3-4110-b992-3f4c6d365799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8XrNwDZjK4fn",
        "colab_type": "code",
        "outputId": "8ca8f2c9-35f0-4d82-a824-299cb0c646ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install cython\n",
        "!pip3 install tables\n",
        "!pip3 install statsmodels\n",
        "!pip3 install -q keras\n",
        "!pip3 install gensim\n",
        "!pip3 install nltk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.6)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (3.4.4)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from tables) (1.14.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tables) (1.11.0)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables) (2.6.9)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from statsmodels) (0.22.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy->statsmodels) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.4 in /usr/local/lib/python3.6/dist-packages (from patsy->statsmodels) (1.14.6)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->statsmodels) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->statsmodels) (2018.9)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.128)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.128 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.128)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.128->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.128->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fcATxs2UJ_ZL",
        "colab_type": "code",
        "outputId": "8326aebd-f367-4c29-faa6-1598cb58bb5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, CuDNNLSTM, Activation, Lambda, Dense, LeakyReLU, Conv1D,GlobalAveragePooling1D\n",
        "from keras.layers import Dropout, Bidirectional,Concatenate, BatchNormalization, Flatten\n",
        "from keras import backend as K, regularizers\n",
        "from keras import optimizers, regularizers, initializers\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from keras.constraints import maxnorm\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Tnofh6PLqSC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ratio = 6\n",
        "data_dir = 'drive/My Drive/'\n",
        "data_file = 'drive/My Drive/5minNo_normalized_data.h5'\n",
        "\n",
        "num_prev_values = 12\n",
        "start = [30]\n",
        "num_classes = 10\n",
        "cutoff = []\n",
        "# data_dir = 'drive/My Drive/btp/sem2_start/Prediction/'\n",
        "# data_file = 'drive/My Drive/btp/sem2_start/Prediction/No_normalized_data.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IQPrhthsDKL9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_hdf(data_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vTOmQMh6DQrp",
        "colab_type": "code",
        "outputId": "757cd72c-04d7-48cb-a020-5ffdf3c59c71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>num_rev</th>\n",
              "      <th>avg_rat</th>\n",
              "      <th>actualdis</th>\n",
              "      <th>dealdis</th>\n",
              "      <th>timeRem</th>\n",
              "      <th>num_type</th>\n",
              "      <th>recordtime</th>\n",
              "      <th>fixedEffects</th>\n",
              "      <th>day</th>\n",
              "      <th>...</th>\n",
              "      <th>day*avg_rat</th>\n",
              "      <th>dealdis*actualdis</th>\n",
              "      <th>num_type*actualdis</th>\n",
              "      <th>day*actualdis</th>\n",
              "      <th>num_type*dealdis</th>\n",
              "      <th>day*dealdis</th>\n",
              "      <th>day*num_type</th>\n",
              "      <th>deal_id</th>\n",
              "      <th>asin</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>4.513926</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>28467046.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.513926</td>\n",
              "      <td>907.57313</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0013c9a8</td>\n",
              "      <td>B06XKFY3FR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>4.513926</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>28153391.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.513926</td>\n",
              "      <td>907.57313</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0013c9a8</td>\n",
              "      <td>B06XKFY3FR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>4.513926</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>27840476.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.513926</td>\n",
              "      <td>907.57313</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0013c9a8</td>\n",
              "      <td>B06XKFY3FR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>4.513926</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>27516851.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.513926</td>\n",
              "      <td>907.57313</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0013c9a8</td>\n",
              "      <td>B06XKFY3FR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>4.513926</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>27193850.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.513926</td>\n",
              "      <td>907.57313</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>28.387097</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>31.971326</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0013c9a8</td>\n",
              "      <td>B06XKFY3FR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   claim  num_rev   avg_rat  actualdis    dealdis     timeRem  num_type  \\\n",
              "0    0.0     92.0  4.513926  28.387097  31.971326  28467046.0       1.0   \n",
              "1    0.0     92.0  4.513926  28.387097  31.971326  28153391.0       1.0   \n",
              "2    0.0     92.0  4.513926  28.387097  31.971326  27840476.0       1.0   \n",
              "3    0.0     92.0  4.513926  28.387097  31.971326  27516851.0       1.0   \n",
              "4    0.0     92.0  4.513926  28.387097  31.971326  27193850.0       1.0   \n",
              "\n",
              "   recordtime  fixedEffects  day ...  day*avg_rat  dealdis*actualdis  \\\n",
              "0         2.0           0.0  1.0 ...     4.513926          907.57313   \n",
              "1         2.0           0.0  1.0 ...     4.513926          907.57313   \n",
              "2         2.0           0.0  1.0 ...     4.513926          907.57313   \n",
              "3         2.0           0.0  1.0 ...     4.513926          907.57313   \n",
              "4         2.0           0.0  1.0 ...     4.513926          907.57313   \n",
              "\n",
              "   num_type*actualdis  day*actualdis  num_type*dealdis  day*dealdis  \\\n",
              "0           28.387097      28.387097         31.971326    31.971326   \n",
              "1           28.387097      28.387097         31.971326    31.971326   \n",
              "2           28.387097      28.387097         31.971326    31.971326   \n",
              "3           28.387097      28.387097         31.971326    31.971326   \n",
              "4           28.387097      28.387097         31.971326    31.971326   \n",
              "\n",
              "   day*num_type   deal_id        asin  y  \n",
              "0           1.0  0013c9a8  B06XKFY3FR  0  \n",
              "1           1.0  0013c9a8  B06XKFY3FR  0  \n",
              "2           1.0  0013c9a8  B06XKFY3FR  0  \n",
              "3           1.0  0013c9a8  B06XKFY3FR  0  \n",
              "4           1.0  0013c9a8  B06XKFY3FR  0  \n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "mY_v1LLKDSnM",
        "colab_type": "code",
        "outputId": "f6a21f57-1ea4-4c2e-b894-520d657832d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "df.columns\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4106495, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "xLhEFrFhOZkF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_per_claim(df):\n",
        "\n",
        "\tclaim = {}\n",
        "\n",
        "\tfor index, row in df.iterrows():\n",
        "\n",
        "\t\tdeal_id = row['deal_id']\n",
        "\n",
        "\t\tif(deal_id in claim):\n",
        "\t\t\tclaim[deal_id].append(row[0])\n",
        "\t\telse:\n",
        "\t\t\tclaim[deal_id] = [row[0]]\n",
        "\n",
        "\treturn claim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xodjYNw68e-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def x_value(df, num_prev_values, start, claim):\n",
        "\n",
        "\tx = [[]]\n",
        "\ty = []\n",
        "\tx = df.iloc[:, [0, 1, 2, 3, 4, 5, 6, 9\\\n",
        "\t \t# 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30 \\\n",
        "\t \t]].values\n",
        "\n",
        "\ty = df.iloc[:, [0]].values\n",
        "\t\n",
        "\tactual_x = [[]]\n",
        "\tactual_y = []\n",
        "\n",
        "\tfor i in range(len(x)):\n",
        "\n",
        "\t\tperClaim = []\n",
        "\t\tasin = (df.iloc[[i]]['deal_id'].values)[0]\n",
        "\t\tperClaim = claim.get(asin)\n",
        "\t\tidx = perClaim.index(x[i][0])\n",
        "\t\t\n",
        "\t\tfor j in range(len(start)):\n",
        "\t\t\n",
        "\t\t\tl = []\n",
        "\t\t\tif((idx - start[j] - num_prev_values + 1) < 0):\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\tl = (perClaim[(idx-start[j]-num_prev_values+1):(idx-start[j]+1)])\n",
        "\n",
        "\t\t\tfor k in range(len(x[i]) - 1):\n",
        "\t\t\t\tl.append(x[i][k])\n",
        "\n",
        "\t\t\tl.append(start[j])\n",
        "\t\t\tactual_x.append(l)\n",
        "\t\t\tactual_y.append(y[i])\n",
        "\n",
        "\tactual_y = np.asarray(actual_y)\n",
        "\t\n",
        "\treturn actual_x, actual_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4b4b1jfNvNB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def y_value(y, num_classes, cutoff):\n",
        "\n",
        "  if(len(cutoff) == 0):\n",
        "    \n",
        "    cutoff_pt = 100/num_classes\n",
        "    num = int(num_classes/cutoff_pt)\n",
        "    for i in range(0, num_classes):\n",
        "      y[(y >= i*cutoff_pt) & (y < (i+1)*cutoff_pt)] = i    \n",
        "    y[y == 100] = num_classes - 1\n",
        "\n",
        "  else:\n",
        "    \n",
        "    y[y <= cutoff[0]] = 0\n",
        "    for i in range(1, num_classes):\n",
        "      y[(y > cutoff[i-1]) & (y <= cutoff[i])] = i\n",
        "\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gYEOrR3a7LBQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def equalSplit(x, y, ratio, num_classes):\n",
        "\n",
        "  leny = []\n",
        "  mini = np.count_nonzero(y==0)\n",
        "\n",
        "  for i in range(num_classes):\n",
        "    val = np.count_nonzero(y==i)\n",
        "    leny.append(val)\n",
        "    if(val != 0 and mini > val):\n",
        "      mini = val\n",
        "\n",
        "  y0 = y[np.where(y == 0), :][0]\n",
        "  x0 = x[np.where(y == 0), :][0]\n",
        "  index = np.random.choice(y0.shape[0], min(ratio*mini, leny[0]), replace = False)\n",
        "  x0 = x0[index]\n",
        "  y0 = y0[index]\n",
        "\n",
        "  y1 = y[np.where(y == 1), :][0]\n",
        "  x1 = x[np.where(y == 1), :][0]\n",
        "  index = np.random.choice(y1.shape[0], min(ratio*mini, leny[1]), replace = False)\n",
        "  x1 = x1[index]\n",
        "  y1 = y1[index]\n",
        "\n",
        "  actual_x = np.vstack((x0, x1))\n",
        "  actual_y = np.vstack((y0, y1))\n",
        "\n",
        "  for i in range(2, num_classes):\n",
        "\n",
        "    y_prime = []\n",
        "    x_prime = []\n",
        "    y_prime = y[np.where(y == i), :][0]\n",
        "    x_prime = x[np.where(y == i), :][0]\n",
        "\n",
        "    if(leny[i] == 0):\n",
        "      print(i)\n",
        "      continue\n",
        "\n",
        "    index = np.random.choice(y_prime.shape[0], min(ratio*mini, leny[i]), replace = False)\n",
        "\n",
        "    x_prime = x_prime[index]\n",
        "    y_prime = y_prime[index]\n",
        "    actual_x = np.vstack((actual_x, x_prime))\n",
        "    actual_y = np.vstack((actual_y, y_prime))\n",
        "\n",
        "  return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVdn3H837N83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def StandardModel(numFeatures, Loss, optimizer):\n",
        "\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(12, input_dim = numFeatures, activation = 'relu'))\n",
        "\tmodel.add(Dense(8, activation = 'relu'))\n",
        "\tmodel.add(Dense(5, activation = 'softmax'))\n",
        "\tmodel.compile(loss = Loss, optimizer = optimizer, metrics = ['accuracy'])\n",
        "\t# model.fit(X, Y, epochs=150, batch_size=10,  verbose=2)\n",
        "\t# predictions = model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fjaMPHAl7Qzr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def define_model(num_classes):\n",
        "\n",
        "\tinput = Input(shape = INPUT_SHAPE_1, dtype = 'float32', name = 'features')\n",
        "\n",
        "\tx = Dense(200, kernel_regularizer = regularizers.l2(1e-3) ,name = 'Fully_Connected_Layer_1')(input)\n",
        "\tx = BatchNormalization()(x)\n",
        "\tx = LeakyReLU(alpha=0.01)(x)\n",
        "\tx = Dropout(DROPOUT,  name = 'Dropout_Regularization_1')(x)\n",
        "\n",
        "\tx = Dense(150, kernel_regularizer = regularizers.l2(1e-3), name = 'Fully_Connected_Layer_2')(x)\n",
        "\tx = BatchNormalization()(x)\n",
        "\tx = LeakyReLU(alpha=0.01)(x)\n",
        "\tx = Dropout(DROPOUT,  name = 'Dropout_Regularization_2')(x)\n",
        "\n",
        "\tx = Dense(90, kernel_regularizer = regularizers.l2(1e-3), name = 'Fully_Connected_Layer_3')(x)\n",
        "\tx = BatchNormalization()(x)\n",
        "\tx = LeakyReLU(alpha=0.01)(x)\n",
        "\tx = Dropout(DROPOUT,  name = 'Dropout_Regularization_3')(x)\n",
        "\n",
        "\tx = Dense(50, kernel_regularizer = regularizers.l2(1e-3), name = 'Fully_Connected_Layer_4')(x)\n",
        "\tx = BatchNormalization()(x)\n",
        "\tx = LeakyReLU(alpha=0.01)(x)\n",
        "\tx = Dropout(DROPOUT,  name = 'Dropout_Regularization_4')(x)\n",
        "\n",
        "\toutput = Dense(num_classes, activation = 'softmax', name = 'Fully_Connected_Layer_5')(x)\n",
        "\n",
        "\tmodel = Model(inputs = [input], outputs = [output], name = 'my_model')\n",
        "\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3zpAsWCWh3rN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def define_model_2(num_classes):\n",
        "\n",
        "  input = Input(shape = INPUT_SHAPE_1, dtype = 'float32', name = 'features')\n",
        "\n",
        "  x = Dense(1024 ,name = 'Fully_Connected_Layer_0')(input)\n",
        "  # \tx = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.01)(x)\n",
        "\n",
        "\n",
        "  x = Dense(512 ,name = 'Fully_Connected_Layer_1')(x)\n",
        "  # \tx = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.01)(x)\n",
        "  # \tx = Dropout(DROPOUT,  name = 'Dropout_Regularization_1')(x)\n",
        "\n",
        "  x = Dense(256, name = 'Fully_Connected_Layer_2')(x)\n",
        "  # \tx = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.01)(x)\n",
        "  # \tx = Dropout(DROPOUT,  name = 'Dropout_Regularization_2')(x)\n",
        "\n",
        "  x = Dense(128, name = 'Fully_Connected_Layer_3')(x)\n",
        "  # \tx = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.01)(x)\n",
        "  # \tx = Dropout(DROPOUT,  name = 'Dropout_Regularization_3')(x)\n",
        "\n",
        "  x = Dense(64, name = 'Fully_Connected_Layer_4')(x)\n",
        "  # \tx = BatchNormalization()(x)\n",
        "  x = LeakyReLU(alpha=0.01)(x)\n",
        "  # \tx = Dropout(DROPOUT,  name = 'Dropout_Regularization_4')(x)\n",
        "\n",
        "  output = Dense(num_classes, activation = 'softmax', name = 'Fully_Connected_Layer_5')(x)\n",
        "\n",
        "  model = Model(inputs = [input], outputs = [output], name = 'my_model')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-yxb8otF7T3W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_model(X_train, X_val, Y_train, Y_val, model):\n",
        "\n",
        "\tprint(model.summary())\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer = optimizers.Adam(), metrics=['accuracy'])\n",
        "\tearlystop = EarlyStopping(monitor = 'val_loss', patience = PAT)\n",
        "\tcheck_pt = ModelCheckpoint(data_dir + 'model_.h5', save_best_only=True)\n",
        "\tcallbacks_list = [earlystop, check_pt]\n",
        "\n",
        "\ttrained_model = model.fit(X_train, [Y_train], epochs = EPOCHS, batch_size = BATCH_SIZE, shuffle = True, \\\n",
        "\t\t\t\t\t\t\t\tvalidation_data = [X_val, [Y_val]], callbacks = callbacks_list)\n",
        "\n",
        "\treturn trained_model, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5S1mcoudiJNI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_model_2(X_train, X_val, Y_train, Y_val, model):\n",
        "\n",
        "\tprint(model.summary())\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer = optimizers.Adam(), metrics=['accuracy'])\n",
        "# \tearlystop = EarlyStopping(monitor = 'val_loss', patience = PAT)\n",
        "# \tcheck_pt = ModelCheckpoint(data_dir + 'model_.h5', save_best_only=True)\n",
        "# \tcallbacks_list = [earlystop, check_pt]\n",
        "\n",
        "\ttrained_model = model.fit(X_train, [Y_train], epochs = EPOCHS, batch_size = BATCH_SIZE, shuffle = True, \\\n",
        "\t\t\t\t\t\t\t\tvalidation_data = [X_val, [Y_val]])\n",
        "\n",
        "\treturn trained_model, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k8u_HJFb7Wy3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_history(trained_model):\n",
        "\n",
        "  fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "\n",
        "  axs[0].plot(trained_model.history['loss'])\n",
        "  axs[0].plot(trained_model.history['val_loss'])\n",
        "  axs[0].set_title('Model Loss')\n",
        "  axs[0].set_ylabel('Loss')\n",
        "  axs[0].set_xlabel('Epoch')\n",
        "  axs[0].legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "  axs[1].plot(trained_model.history['acc'])\n",
        "  axs[1].plot(trained_model.history['val_acc'])\n",
        "  axs[1].set_title('Model Accuracy')\n",
        "  axs[1].set_ylabel('Accuracy')\n",
        "  axs[1].set_xlabel('Epoch')\n",
        "  axs[1].legend(['Train', 'Validation'], loc='upper right')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdvh04T_7ZeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "claim = get_per_claim(df)\n",
        "x, y = x_value(df, num_prev_values, start, claim)\n",
        "store_y = y\n",
        "x = x[1:]\n",
        "x = np.asarray(x)\n",
        "dfx = pd.DataFrame(x)\n",
        "dfx.to_hdf(data_dir + '12_30_x_values.h5', key = 'dfx', mode = 'w')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WvS0zYeuN8zf",
        "colab_type": "code",
        "outputId": "5e33e061-673f-4271-8004-b68e55d53108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(x), len(y))\n",
        "y = y_value(y, num_classes, cutoff)\n",
        "dfy = pd.DataFrame(y)\n",
        "dfy.to_hdf(data_dir + '12_30_y.h5', key = 'dfy', mode = 'w')\n",
        "print('x and y created')\n",
        "x, y = equalSplit(x, y, ratio, num_classes)\n",
        "print('x and y equally splitted')\n",
        "\n",
        "X_scaled = preprocessing.scale(x)\n",
        "y = y.astype(int)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.4, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.2, random_state=42)\n",
        "\n",
        "# print(np.count_nonzero(y_train == 4))\n",
        "# print(np.count_nonzero(y_train == 3))\n",
        "# print(np.count_nonzero(y_train == 2))\n",
        "# print(np.count_nonzero(y_train == 1))\n",
        "# print(np.count_nonzero(y_train == 0))\n",
        "\n",
        "y_train = np.squeeze(np.eye(num_classes)[y_train.reshape(-1)])\n",
        "print(len(X_scaled), len(y))\n",
        "y_val = np.squeeze(np.eye(num_classes)[y_val.reshape(-1)])\n",
        "y_test = np.squeeze(np.eye(num_classes)[y_test.reshape(-1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1637685 1637685\n",
            "x and y created\n",
            "x and y equally splitted\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:180: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  warnings.warn(\"Numerical issues were encountered \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1637685 1637685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NQGSxnkjODVo",
        "colab_type": "code",
        "outputId": "1721dc0a-1adf-45ce-c446-c1300341da31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1066
        }
      },
      "cell_type": "code",
      "source": [
        "# print('Training started')\n",
        "# clf = MLPClassifier()\n",
        "# clf.fit(x_train, y_train)\n",
        "\n",
        "# print('Testing Started')\n",
        "# y_pred = clf.predict(x_train)\n",
        "# print('Train Accuracy - ', accuracy_score(y_train, y_pred))\n",
        "# y_pred = clf.predict(x_test)\n",
        "# print('Test Accuracy - ', accuracy_score(y_test, y_pred))\n",
        "# print(len(x_train), len(x_test))\n",
        "\n",
        "INPUT_SHAPE_1 = (8 + num_prev_values, )\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 512\n",
        "DROPOUT = 0.15\n",
        "PAT = 10\n",
        "\n",
        "K.clear_session()\n",
        "model = define_model_2(num_classes)\n",
        "trained_model, model = run_model_2(x_train, x_val, y_train, y_val, model)\n",
        "model_history(trained_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "features (InputLayer)        (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "Fully_Connected_Layer_0 (Den (None, 1024)              21504     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "Fully_Connected_Layer_1 (Den (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "Fully_Connected_Layer_2 (Den (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "Fully_Connected_Layer_3 (Den (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "Fully_Connected_Layer_4 (Den (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "Fully_Connected_Layer_5 (Den (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 719,434\n",
            "Trainable params: 719,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 982611 samples, validate on 524059 samples\n",
            "Epoch 1/1\n",
            "982611/982611 [==============================] - 24s 24us/step - loss: 0.1170 - acc: 0.9548 - val_loss: 0.0559 - val_acc: 0.9768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAAFMCAYAAACQ8b6mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "otpZIsSCHQ9W",
        "colab_type": "code",
        "outputId": "43c81e5d-3e9e-43cd-f2d3-551149442742",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(x_test)).argmax(axis=-1)\n",
        "y_test = [np.where(r==1)[0][0] for r in y_test]\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9769873678586422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W8Hy6EPtga-2",
        "colab_type": "code",
        "outputId": "68dd5d78-a816-4017-9d0b-22249d326d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98     38216\n",
            "           1       1.00      0.96      0.98     29866\n",
            "           2       0.99      1.00      1.00     21864\n",
            "           3       1.00      0.98      0.99     12892\n",
            "           4       0.98      0.99      0.99      9496\n",
            "           5       0.99      1.00      0.99      6567\n",
            "           6       1.00      0.91      0.95      5164\n",
            "           7       0.75      1.00      0.86      3392\n",
            "           8       0.91      0.71      0.80      2431\n",
            "           9       1.00      0.85      0.92      1127\n",
            "\n",
            "   micro avg       0.98      0.98      0.98    131015\n",
            "   macro avg       0.96      0.94      0.95    131015\n",
            "weighted avg       0.98      0.98      0.98    131015\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vx1QgyYMhEjV",
        "outputId": "8a264a3b-18d0-4de8-bb2a-efafb7f81563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(x_train)).argmax(axis=-1)\n",
        "y_train = [np.where(r==1)[0][0] for r in y_train]\n",
        "print(accuracy_score(y_pred, y_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9770529741678039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kIbsHbqahEjr",
        "outputId": "4ac2e57b-f327-48cd-bbfc-63dc7d91b423",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_train, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98    288196\n",
            "           1       1.00      0.95      0.98    224022\n",
            "           2       0.99      1.00      1.00    162757\n",
            "           3       1.00      0.98      0.99     96362\n",
            "           4       0.98      1.00      0.99     71291\n",
            "           5       0.99      1.00      0.99     49407\n",
            "           6       1.00      0.91      0.95     37761\n",
            "           7       0.75      1.00      0.86     25809\n",
            "           8       0.92      0.71      0.80     18783\n",
            "           9       1.00      0.86      0.92      8223\n",
            "\n",
            "   micro avg       0.98      0.98      0.98    982611\n",
            "   macro avg       0.96      0.94      0.95    982611\n",
            "weighted avg       0.98      0.98      0.98    982611\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kK44HWGch3W_",
        "outputId": "6ae8e515-e3ca-49b0-c462-3cf1b537daca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(x_val)).argmax(axis=-1)\n",
        "y_val = [np.where(r==1)[0][0] for r in y_val]\n",
        "print(accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9768117711937014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z6R9uz65h3XJ",
        "outputId": "910ae711-8d06-458b-8ed0-b6d636bb196d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98    153420\n",
            "           1       1.00      0.95      0.98    119221\n",
            "           2       0.99      1.00      1.00     86768\n",
            "           3       1.00      0.98      0.99     52357\n",
            "           4       0.98      1.00      0.99     37993\n",
            "           5       0.99      1.00      0.99     26077\n",
            "           6       1.00      0.91      0.95     20217\n",
            "           7       0.75      1.00      0.86     13491\n",
            "           8       0.92      0.70      0.80     10043\n",
            "           9       1.00      0.86      0.92      4472\n",
            "\n",
            "   micro avg       0.98      0.98      0.98    524059\n",
            "   macro avg       0.96      0.94      0.95    524059\n",
            "weighted avg       0.98      0.98      0.98    524059\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YRjxjnvprm86",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SIqFJ9cV0Fnh",
        "colab_type": "code",
        "outputId": "82d9e36f-15fc-4e8b-e70e-300e01310f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(unique, counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9] [288196 224022 162757  96362  71291  49407  37761  25809  18783   8223]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}